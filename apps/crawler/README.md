# crawler

Crawler browses the student portfolio websites acting as user and stores the scraped data to the database for the research purposes.

## Get started

install dependencies

```bash
npm i
```

start crawl

```bash
npm run start
```

continue last crawl

```bash
CRAWLEE_PURGE_ON_START=0 npm start
```
